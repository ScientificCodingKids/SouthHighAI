{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394c3ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create animation on real-time updating data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback as tb\n",
    "import time\n",
    "\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611e7c4",
   "metadata": {},
   "source": [
    "# Linear regression (on 2-variable function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eff2946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR function -- along with NAND (Not-and), OR, AND\n",
    "# truth tables\n",
    "\n",
    "\n",
    "# input variable values on training data\n",
    "\n",
    "train_data = np.array(\n",
    "    [\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [1, 1]])\n",
    "\n",
    "# output variable values on training data -- pick one to train a specific function\n",
    "\n",
    "# for this example, there is NO separate testing data (input only has finite (4) possibilities)\n",
    "\n",
    "# it is a huge blow to perceptron based method as it cannot even behave on training data (untrainable)!\n",
    "\n",
    "# note this is an inheritent issue of the model, not an issue of a particular training method.\n",
    "\n",
    "target_xor = np.array(\n",
    "    [\n",
    "        [0],\n",
    "        [1],\n",
    "        [1],\n",
    "        [0]])\n",
    "\n",
    "target_nand = np.array(\n",
    "    [\n",
    "        [1],\n",
    "        [1],\n",
    "        [1],\n",
    "        [0]])\n",
    "\n",
    "target_or = np.array(\n",
    "    [\n",
    "        [0],\n",
    "        [1],\n",
    "        [1],\n",
    "        [1]])\n",
    "\n",
    "target_and = np.array(\n",
    "    [\n",
    "        [0],\n",
    "        [0],\n",
    "        [0],\n",
    "        [1]])\n",
    "\n",
    "target_first = np.array(\n",
    "    [\n",
    "        [1],\n",
    "        [1],\n",
    "        [0],\n",
    "        [0]\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42999531",
   "metadata": {},
   "source": [
    "## Perceptron class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f29f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "# original code is See https://towardsdatascience.com/how-neural-networks-solve-the-xor-problem-59763136bdd7\n",
    "# we added visualization\n",
    "color_scale = [[0., 'gold'], [0.5, 'mediumturquoise'], [1., 'lightsalmon']]\n",
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    Create a perceptron.\n",
    "    train_data: A 4x2 matrix with the input data.\n",
    "    target: A 4x1 matrix with the perceptron's expected outputs\n",
    "    lr: the learning rate. Defaults to 0.01\n",
    "    input_nodes: the number of nodes in the input layer of the perceptron.\n",
    "        Should be equal to the second dimension of train_data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_data, target, lr=0.01, input_nodes=2, h=0.01, fig=None):\n",
    "        self.train_data = train_data\n",
    "        self.target = target\n",
    "        self.lr = lr\n",
    "        self.input_nodes = input_nodes\n",
    "\n",
    "        # randomly initialize the weights and set the bias to -1.\n",
    "        self.w = np.random.uniform(size=self.input_nodes)\n",
    "        self.b = -1\n",
    "\n",
    "        # node_val hold the values of each node at a given point of time.\n",
    "        self.node_val = np.zeros(self.input_nodes)\n",
    "\n",
    "        self.fig = fig # go.Figure()\n",
    "        \n",
    "        self.x_range = np.arange(-0.1, 1.1, h)\n",
    "        self.y_range = np.arange(-0.1, 1.1, h)\n",
    "\n",
    "        # creating a mesh to plot decision boundary\n",
    "        xx, yy = np.meshgrid(self.x_range, self.y_range, indexing='ij')\n",
    "        Z = np.array([[self.classify([x, y]) for x in self.x_range] for y in self.y_range])\n",
    "        self.trace_contour = go.Contour(\n",
    "            z=Z, colorscale=color_scale, x=self.x_range, y=self.y_range\n",
    "        )\n",
    "        # using the contourf function to create the plot\n",
    "        self.fig.add_trace(self.trace_contour)\n",
    "        \n",
    "        self.fig.update_layout(title = f\"w={self.w}, b={self.b}\")\n",
    "        \n",
    "        \n",
    "        display(self.fig)\n",
    "\n",
    "        \n",
    "    def _gradient(self, node, exp, output):\n",
    "        \"\"\"\n",
    "        Return the gradient for a weight.\n",
    "        This is the value of delta-w.\n",
    "        \"\"\"\n",
    "        return node * (exp - output)\n",
    "\n",
    "    def update_weights(self, exp, output):\n",
    "        \"\"\"\n",
    "        Update weights and bias based on their respective gradients\n",
    "        \"\"\"\n",
    "        for i in range(self.input_nodes):\n",
    "            self.w[i] += self.lr * self._gradient(self.node_val[i], exp, output)\n",
    "\n",
    "        # the value of the bias node can be considered as being 1 and the weight between this node\n",
    "        # and the output node being self.b\n",
    "        self.b += self.lr * self._gradient(1, exp, output)\n",
    "\n",
    "    def forward(self, datapoint):\n",
    "        \"\"\"\n",
    "        One forward pass through the perceptron.\n",
    "        Implementation of \"wX + b\".\n",
    "        \"\"\"\n",
    "        return self.b + np.dot(self.w, datapoint)\n",
    "\n",
    "    def classify(self, datapoint):\n",
    "        \"\"\"\n",
    "        Return the class to which a datapoint belongs based on\n",
    "        the perceptron's output for that point.\n",
    "        \"\"\"\n",
    "        if self.forward(datapoint) >= 0:\n",
    "            return 1\n",
    "\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    def train(self, max_iters=100):\n",
    "        \"\"\"\n",
    "        Train a single layer perceptron.\n",
    "        \"\"\"\n",
    "        # the number of consecutive correct classifications\n",
    "        correct_counter = 0\n",
    "\n",
    "        n_iters = 0 # number of training data points seen\n",
    "        \n",
    "        for train, target in cycle(zip(self.train_data, self.target)):\n",
    "            # end if all points are correctly classified\n",
    "            #print(f\"start {n_iters}\")\n",
    "            if correct_counter == len(self.train_data) or n_iters == max_iters:\n",
    "                print(\"quit\")\n",
    "                break\n",
    "\n",
    "            n_iters += 1\n",
    "            \n",
    "            output = self.classify(train)\n",
    "            self.node_val = train\n",
    "\n",
    "            if output == target:\n",
    "                correct_counter += 1\n",
    "            else:\n",
    "                # if incorrectly classified, update weights and reset correct_counter\n",
    "                self.update_weights(target, output)\n",
    "                correct_counter = 0\n",
    "        \n",
    "            if n_iters > 0:\n",
    "                # Z = np.array([[ 1./ (1. + np.exp(self.forward([x, y])) ) for x in self.x_range] for y in self.y_range])\n",
    "                Z = np.array([[ self.classify([x, y]) for x in self.x_range] for y in self.y_range])\n",
    "\n",
    "                #self.fig.update_traces(z=Z)\n",
    "                #self.fig.update_layout(title = f\"w={self.w}, b={self.b}, n_iters={n_iters}\")\n",
    "\n",
    "                #print(f\"iter: {n_iters}, w= {self.w}\")\n",
    "                with self.fig.batch_update():\n",
    "                    self.fig.data[0].z = Z\n",
    "                    self.fig.layout.title = f\"w={self.w}, b={self.b}, n_iters={n_iters}, cumulative success={correct_counter}\"\n",
    "                \n",
    "                time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a4292",
   "metadata": {},
   "source": [
    "## train the XOR function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7899556d",
   "metadata": {},
   "source": [
    "![XOR function](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*aN7_uKSN8iWUktGOKa1Vgg.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a955e5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbc8a27fb1543839f666ff12f147657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'colorscale': [[0.0, 'gold'], [0.5, 'mediumturquoise'], [1.0,\n",
       "                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quit\n"
     ]
    }
   ],
   "source": [
    "p_xor = Perceptron(train_data, target_xor, fig=go.FigureWidget())\n",
    "p_xor.train( max_iters=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= f(x; w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcaa861",
   "metadata": {},
   "source": [
    "## Questions\n",
    "- What is maximum cumulative success value? How to interprete this value?\n",
    "- Cumulative success = 0 means the model get the output for all four inputs wrong. Since the output is either 0 or 1. Can you just \"flip\" the output value to make the model to work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a0f64",
   "metadata": {},
   "source": [
    "## train NAND function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6fcf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5396bae53b54692a69fbba2c210be3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'colorscale': [[0.0, 'gold'], [0.5, 'mediumturquoise'], [1.0,\n",
       "                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quit\n"
     ]
    }
   ],
   "source": [
    "p_nand = Perceptron(train_data, target_nand, fig=go.FigureWidget())\n",
    "p_nand.train( max_iters=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4694b",
   "metadata": {},
   "source": [
    "## train FIRST function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b631b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc4b0e35de743599bb3ecfc278f264e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'colorscale': [[0.0, 'gold'], [0.5, 'mediumturquoise'], [1.0,\n",
       "                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quit\n"
     ]
    }
   ],
   "source": [
    "# FIRST function: it takes the \"first\" component from the 2-element input, x= (a, b) -> a\n",
    "p_first = Perceptron(train_data, target_first, fig=go.FigureWidget())\n",
    "p_first.train( max_iters=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9fbdf2",
   "metadata": {},
   "source": [
    "## Questions\n",
    "- Does above model match your intuition?\n",
    "- How many different possible model fittings exist? Is it finite or infinite? How do you define the \"best\" fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf92de",
   "metadata": {},
   "source": [
    "# Bonus\n",
    "\n",
    "Interactive visualization -- the following code snipplet can be very handy when we are doing data exploration. They are not dependent on linear regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14217b",
   "metadata": {},
   "source": [
    "## Updating graph in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc2bd068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb9574d5c5340988c808765a25f5ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'scatter', 'uid': '8738b6b7-8af7-4f7b-9a74-a5f9d167dc06', 'x': [1, 2, 3],…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "figg = go.FigureWidget()\n",
    "\n",
    "# Add some traces\n",
    "figg.add_trace(go.Scatter(x=[1, 2, 3], y=[4, 5, 6]))\n",
    "display(figg)  # multiple calls will render multiple images! figg.show() won't animate\n",
    "\n",
    "# Update the traces in a loop\n",
    "for i in range(3):\n",
    "    with figg.batch_update():\n",
    "        figg.data[0].y = np.sin( (i + 1) * np.array(figg.data[0].x) )\n",
    "\n",
    "    time.sleep(2)\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59722e",
   "metadata": {},
   "source": [
    "## Use widget control to update params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b8ccc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7eccfddebe64458849d3b03870e197f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'scatter', 'uid': '1432612a-372f-4275-95cd-0200267549cf', 'x': [1, 2, 3],…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "fig3 = go.FigureWidget()\n",
    "\n",
    "fig3.add_trace(go.Scatter(x=[1, 2, 3], y=[4, 5, 6]))\n",
    "\n",
    "display(fig3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcf60d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08595dbe58534900974f0b62875595ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=3.6, description='a', max=4.0, min=1.0, step=0.01), FloatSlider(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs=np.linspace(0, 6, 100)\n",
    "\n",
    "@interact(a=(1.0, 4.0, 0.01), b=(0, 10.0, 0.01), color=['red', 'green', 'blue'])\n",
    "def update(a=3.6, b=4.3, color='blue'):\n",
    "    with fig3.batch_update():\n",
    "        fig3.data[0].x=xs\n",
    "        fig3.data[0].y=np.sin(a*xs-b)\n",
    "        fig3.data[0].line.color=color"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
