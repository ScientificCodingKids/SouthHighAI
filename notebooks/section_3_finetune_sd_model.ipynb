{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d061425",
   "metadata": {},
   "source": [
    "# Pokemon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb235fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback as tb\n",
    "import time\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import interact\n",
    "from PIL import Image, ImageFilter  # PIL is a popular image processing package \"pillow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a08362",
   "metadata": {},
   "source": [
    "![Sample images](https://lambdalabs.com/hs-fs/hubfs/2.%20Images/Images%20-%20Blog%20Posts/2022%20-%20Blog%20Images/image--3-.png?width=1152&height=768&name=image--3-.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c52310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/pokemon (download: 95.05 MiB, generated: 113.89 MiB, post-processed: Unknown size, total: 208.94 MiB) to C:/Users/north/.cache/huggingface/datasets/lambdalabs___parquet/lambdalabs--pokemon-blip-captions-baa94796864cc987/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d68535160494a0f9ae0f715beb61f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc64e7ce12db49c996c486166fb6c71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to C:/Users/north/.cache/huggingface/datasets/lambdalabs___parquet/lambdalabs--pokemon-blip-captions-baa94796864cc987/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"lambdalabs/pokemon-blip-captions\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2984e670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image', 'text']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b0efa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text'],\n",
       "    num_rows: 833\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9434e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9341198af7f4e9981e413a7c889b3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='row_id', max=832), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6628d8d3291040669e8dff816d4917b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'image',\n",
       "              'uid': 'b8797581-2c67-42b7-b337-0f2bb10dfcae',\n",
       "   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# below is slow updating\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#display(noisy_img)\n",
    "pokemon_widget = go.FigureWidget()\n",
    "pokemon_widget.add_trace(go.Image(z=np.array(ds[0][\"image\"])))\n",
    "\n",
    "@interact(row_id=(0, 832, 1), continuous_update=False)\n",
    "def show_sample(row_id=0):\n",
    "    sample = ds[row_id] # each sample consists of an image and a text description\n",
    "    img = sample[\"image\"]\n",
    "    with pokemon_widget.batch_update():\n",
    "        pokemon_widget.data[0].z=np.array(img)\n",
    "        pokemon_widget.update_xaxes(showticklabels=False)\n",
    "        pokemon_widget.update_yaxes(showticklabels=False)\n",
    "        pokemon_widget.layout.title = f\"{row_id}: {sample['text']}\"\n",
    "        \n",
    "display(pokemon_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1886bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c084ca",
   "metadata": {},
   "source": [
    "# Dataset type\n",
    "\n",
    "Iteratable for image and text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955ab83",
   "metadata": {},
   "source": [
    "## a trivial example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be40e9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.arrow_dataset import Dataset\n",
    "img_tensor = np.zeros((100, 512, 512, 3))\n",
    "captions = []\n",
    "for i in range(100):\n",
    "    captions.append(f\"hello: {i}\")\n",
    "    \n",
    "captioned_imgs = {\n",
    "    \"image\": img_tensor,\n",
    "    \"text\": captions\n",
    "}\n",
    "#from datasets import Dataset\n",
    "out = Dataset.from_dict(captioned_imgs)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be64c88d",
   "metadata": {},
   "source": [
    "## robot parts dataset\n",
    "\n",
    "YOU are in charge to create this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194229b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose we store 5 images in d:\\dev\\ai\\SouthHighAI\\data\\VRCRobots folder and a single ImageText.txt there describes all images (1 image per line).\n",
    "# The images are obtained by Google \"VEX VRC Robot\". Their sizes vary and no guarantee they are 512x512 or even square.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2608893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.arrow_dataset import Dataset\n",
    "n = 5\n",
    "vrc_folder = r\"d:\\dev\\ai\\SouthHighAI\\data\\VRCRobots\\\\\"\n",
    "\n",
    "with open(vrc_folder + \"ImageText.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "image_caption_dic = {}\n",
    "\n",
    "for line in lines:\n",
    "    toks = line.split(\":\")\n",
    "    if len(toks) != 2:\n",
    "        raise ValueError(f\"ONLY TWO tokens allowed: {line}\")\n",
    "        \n",
    "    i = int(toks[0])\n",
    "    image_caption_dic[i] = toks[1]\n",
    "    \n",
    "vrc_img_tensor = np.zeros( (n, 512, 512, 3) )\n",
    "vrc_captions = image_caption_dic.values()\n",
    "\n",
    "for i in range(1, 6):\n",
    "    img = Image.open(vrc_folder + str(i) + \".png\")\n",
    "    img = img.resize((512, 512), Image.LANCZOS).convert(\"RGB\")\n",
    "    vrc_img_tensor[i-1] = img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7d068e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vrc_captioned_imgs = {\n",
    "    \"image\": vrc_img_tensor,\n",
    "    \"text\": vrc_captions\n",
    "}\n",
    "#from datasets import Dataset\n",
    "vrc_out = Dataset.from_dict(vrc_captioned_imgs)\n",
    "\n",
    "vrc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cfe426a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdfb05249dc424788332e178dbb0404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='row_id', max=4), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651ad31f53694080b97a72d9aa2d2bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'image',\n",
       "              'uid': '3784ea33-9b36-4d70-add9-929cefba1389',\n",
       "   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# below is slow updating\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#display(noisy_img)\n",
    "vrc_widget = go.FigureWidget()\n",
    "vrc_widget.add_trace(go.Image(z=np.array(vrc_out[0][\"image\"])))\n",
    "\n",
    "@interact(row_id=(0, 4, 1), continuous_update=False)\n",
    "def show_vrc_sample(row_id=0):\n",
    "    sample = vrc_out[row_id] # each sample consists of an image and a text description\n",
    "    img = sample[\"image\"]\n",
    "    with pokemon_widget.batch_update():\n",
    "        vrc_widget.data[0].z=np.array(img)\n",
    "        vrc_widget.update_xaxes(showticklabels=False)\n",
    "        vrc_widget.update_yaxes(showticklabels=False)\n",
    "        vrc_widget.layout.title = f\"{row_id}: {sample['text']}\"\n",
    "        \n",
    "display(vrc_widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
